<!DOCTYPE HTML>
<!--
	Massively by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>MO Data portfolio </title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper" class="fade-in">

				<!-- Intro -->
					<div id="intro">
						<h1>Mike Osenya <br> 
						<h3>My data portfolio</h3> 
						</h1>
						<p>Let's make it data!<br>
							
						Highly skilled and results-driven data engineer with over three years of experience designing and implementing 
						scalable data solutions across analytics, data engineering, and quality assurance domains. Proven expertise 
						in building robust ETL pipelines, managing distributed data processing systems, 
						and enabling high-performance analytics using technologies like Apache Spark, Airflow, Databricks, and Azure Data Factory
						
						<br> <a href="https://www.linkedin.com/in/mike-osenya-556329133/">Check out my linkedin profile</a>.</p>
						<ul class="actions">
							<li><a href="#header" class="button icon solid solo fa-arrow-down scrolly">Continue</a></li>
						</ul>
					</div>

				<!-- Header -->
					<header id="header">
						<a href="index.html" class="logo">My projects</a>
					</header>

				<!-- Nav -->
					<nav id="nav">
						<ul class="links">
							<li class="active"><a href="index.html">Sample data projects</a></li>
							<li><a href="generic.html">Business Intelligence</a></li>
							<li><a href="elements.html">Data engineering</a></li>
						</ul>
						<ul class="icons">
							
							
							<li><a href="https://www.linkedin.com/in/mike-osenya-556329133/" class="icon brands fa-linkedin" target="_blank"><span class="label">LinkedIn</span></a></li>
							<li><a href="https://github.com/osenya" class="icon brands fa-github"><span class="label">GitHub</span></a></li>
						</ul>
					</nav>

				<!-- Main -->
					<div id="main">

						<!-- Featured Post -->
							<article class="post featured">
								
									
									<h4> Weather ETL Pipeline using Apache Airflow, Python & Amazon S3 <br /></h4>
									<p>     This project demonstrates the implementation of a modern Extract, Transform, Load (ETL) pipeline using Apache Airflow. 
										The pipeline fetches real-time weather data from the OpenWeatherMap API, transforms it into a clean format, and uploads
										 it directly to an Amazon S3 bucket, automating the end-to-end data flow using Airflow DAGs.</p>
									
	
								
								<img src="images/Airflow 2025-06-25 213655.png" alt="" height="300px" width ="800px" />
								<ul class="actions special">
									<li><a href="https://github.com/osenya/Weather_ETL_using_Airflow" class="button large"> See details of the project </a></li>
								</ul>
							</article>

						<!-- Posts -->
							<section class="posts">
								<article>
									<header>
										<h3><a href="#">Real-Time JSON Data Ingestion Using Databricks Auto Loader<br />
										</a></h3>
									</header>
									<a href="https://databricks-prod-cloudfront.cloud.databricks.com/public/4027ec902e239c93eaaa8714f173bcfc/2728762554867858/4254516994106789/2555577612711057/latest.html" class="image fit"><img src="images/Databricks_autoloader.png" alt="" /></a>
									<p> 
                                                                                This project showcases the implementation of a real-time data ingestion pipeline using Databricks Auto Loader. 
										The pipeline is designed to efficiently process JSON data from a specified source, leveraging the capabilities of 
										Databricks for scalable and reliable data processing.                                                 
									</p>
									<ul class="actions special">
										<li><a href="#" class="button">View project</a></li>
									</ul>
								</article>
								<article>
									<header>
										
										<h3><a href="#"> Data ingestion using Apache Spark and Delta Lake<br />
										</a></h3>
									</header>
									<a href="#" class="image fit"><img src="images/spark_databricks.png" alt="" /></a>
									<p>     This project demonstrates the creation and population of a Bronze Layer in a medallion architecture data lake, 
										focusing on the ingestion and time-stamping of customer data using Apache Spark and Delta Lake within the 
										Databricks environment.				
									</p>
									<ul class="actions special">
										<li><a href="https://databricks-prod-cloudfront.cloud.databricks.com/public/4027ec902e239c93eaaa8714f173bcfc/2728762554867858/2678184107042929/2555577612711057/latest.html">View project</a></li>
									</ul>
								</article>
								<article>
									<header>
										
										<h2><a href="#">Data pipeline <br />
										</a></h2>
									</header>
									<a href="#" class="image fit"><img src="images/pic04.jpg" alt="" /></a>
									<p></p>
									<ul class="actions special">
										<li><a href="#" class="button">View project</a></li>
									</ul>
								</article>
								<article>
									<header>
										
										<h3><a href="#">Incremental Data Transformation Pipeline in Databricks Silver Layer <br />
										</a></h3>
									</header>
									<a href="#" class="image fit"><img src="images/Inc_load.png" alt="" /></a>
									<p> This project demonstrates a robust and scalable Silver Layer transformation pipeline using Apache Spark and Delta Lake 
										on Databricks. It implements incremental data loading, data quality enforcement, business rule transformations, 
										and upserts into a Delta table optimized for downstream analytics. The pipeline follows the medallion architecture,
										processing raw Bronze-layer customer data into refined, query-optimized Silver-layer insights.</p>
									<ul class="actions special">
										<li><a href="https://github.com/osenya/Incremental-data-load-pipeline" class="button">View project</a></li>
									</ul>
								</article>
								
							</section>

						

					</div>

				<!-- Footer -->
					<footer id="footer">
	
						<section class="split contact">
							<section class="alt">
								
							</section>
							<section>
								<h3>Phone</h3>
								<p>0712 518 301 </p>
							</section>
							<section>
								<h3>Email</h3>
								<p><a href="#">mikeosenya@gmailcom</a></p>
							</section>
							
							</section>
						</section>
					</footer>

				<!-- Copyright -->
					<div id="copyright">
						<ul><li>&copy; Mike_Osenya</li></ul>
					</div>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
